# LangChain RAG (Retrieval-Augmented Generation) Project

A comprehensive implementation of RAG using LangChain to create a context-based question-answering system that can retrieve and generate responses from web documentation.

## ğŸš€ Project Overview

This project demonstrates a complete RAG pipeline that:
- **Ingests data** from web sources (LangChain documentation)
- **Processes and chunks** text for optimal retrieval
- **Creates embeddings** and stores them in a vector database
- **Retrieves relevant context** for user queries
- **Generates answers** using OpenAI's GPT models

## ğŸ“ Project Structure

```
Langchain/
â”œâ”€â”€ Project/
â”‚   â””â”€â”€ GENAIApp.ipynb          # Main RAG implementation
â”œâ”€â”€ DataIngestion/
â”‚   â”œâ”€â”€ Data_Ingestion.ipynb    # Web scraping and data loading
â”‚   â”œâ”€â”€ attention.pdf           # Sample PDF document
â”‚   â””â”€â”€ speech.txt              # Sample text file
â”œâ”€â”€ Embeddings/
â”‚   â”œâ”€â”€ embedding.ipynb         # OpenAI embeddings
â”‚   â”œâ”€â”€ HuggingfaceEmbedding.ipynb
â”‚   â””â”€â”€ ollamaembedding.ipynb
â”œâ”€â”€ vector_store/
â”‚   â”œâ”€â”€ FAISS.ipynb            # FAISS vector store implementation
â”‚   â””â”€â”€ Chroma.ipynb           # ChromaDB vector store implementation
â”œâ”€â”€ Data Transformer/
â”‚   â””â”€â”€ Text-Splitting.ipynb   # Text chunking strategies
â”œâ”€â”€ requirements.txt            # Project dependencies
â””â”€â”€ Started.ipynb             # Getting started guide
```

## ğŸ›  Features

- **Web Data Ingestion**: Scrapes content from websites using WebBaseLoader
- **Text Processing**: Intelligent text chunking with RecursiveCharacterTextSplitter
- **Vector Storage**: FAISS integration for efficient similarity search
- **Multiple Embeddings**: Support for OpenAI, HuggingFace, and Ollama embeddings
- **Question Answering**: Context-aware responses using retrieval chains
- **LangChain Integration**: Built with LangChain 1.0 and classic chains

## ğŸ”§ Installation

1. Clone the repository:
```bash
git clone <repository-url>
cd Langchain
```

2. Create a virtual environment:
```bash
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate
```

3. Install dependencies:
```bash
pip install -r requirements.txt
```

4. Set up environment variables:
Create a `.env` file with:
```
OPENAI_API_KEY=your_openai_api_key
LANGCHAIN_API_KEY=your_langchain_api_key
LANGCHAIN_PROJECT=your_project_name
```

## ğŸš€ Usage

### Main RAG Application
Open and run `Project/GENAIApp.ipynb` to see the complete RAG implementation:

1. **Data Ingestion**: Loads content from LangChain documentation
2. **Text Chunking**: Splits documents into manageable chunks
3. **Embedding Creation**: Generates embeddings using OpenAI
4. **Vector Storage**: Stores embeddings in FAISS vector database
5. **Question Answering**: Retrieves context and generates responses

### Example Queries
- "What is integration stuff here?"
- "What is Vertex AI Model Garden and what packages are required?"

## ğŸ“š Key Components

### Data Processing Pipeline
- **WebBaseLoader**: Scrapes web content
- **RecursiveCharacterTextSplitter**: Intelligently chunks text
- **OpenAIEmbeddings**: Creates semantic embeddings

### Vector Storage
- **FAISS**: Facebook AI Similarity Search for efficient retrieval
- **ChromaDB**: Alternative vector database option

### Language Models
- **OpenAI GPT-4o-mini**: Primary language model for generation
- **HuggingFace Models**: Alternative embedding options

## ğŸ”„ RAG Workflow

1. **Ingest** â†’ Load documents from web sources
2. **Transform** â†’ Split text into chunks with overlap
3. **Embed** â†’ Create vector representations
4. **Store** â†’ Save embeddings in vector database
5. **Retrieve** â†’ Find relevant chunks for queries
6. **Generate** â†’ Create contextual responses

## ğŸ“‹ Requirements

```
langchain==1.0.0
langchain-community==0.4
langchain-classic==1.0.0
langchain-openai==1.0.0
langchain-text-splitters==1.0.0
python-dotenv
faiss-cpu
chromadb
sentence-transformers
```

## ğŸ¤ Contributing

Feel free to contribute to this project by:
- Adding new data sources
- Implementing additional embedding models
- Improving the retrieval accuracy
- Adding new vector store options

## ğŸ“„ License

This project is open source and available under the MIT License.

## ğŸ™ Acknowledgments

- Built with [LangChain](https://langchain.com/)
- Powered by [OpenAI](https://openai.com/)
- Vector search by [FAISS](https://github.com/facebookresearch/faiss)
